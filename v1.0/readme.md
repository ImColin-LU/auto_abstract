# 论文助手

#### 基于textrank与seq2seq的标题，关键字，摘要分析项目

------

### 一. 数据及模型说明

1. **数据源：**

   搜狗实验室搜狐新闻语料数据http://www.sogou.com/labs/resource/cs.php

2. **用到的模型源：**

   LTP哈工大语言模型

3. **数据预处理：**

   通过seq2seqAttSum/sougouProcess进行语料数据的预处理。处理时，需要在文件中更改数据生成的目录与名称。其中的处理包括：提取文本标题与内容，对内容进行命名实体替换，生成需要的测试集与训练集。

   > 这里使用了pyltp包，模型路径为ltp_data_v3.4.0

4. **模型搭建训练：**

   seq2seqAttSum下headline.py进行项目训练，项目保存在本目录下的ckpt 文件夹中
   		

### 二. 文件下的文件功能：

- data_utils.py:对文件执行分词、创建词典、生成ID功能（实际运行中 需要更改jinyici对应的路径）
- eval.py :设定了两个文本的评估方式，并计划可视化功能
- headline.py:设定读取函数，创建模型、执行训练功能	
- predict.py:设定了预测的方法
- seq2seq_model.py：设定了seq2seq模型的具体内容		
- sougouProcess.py:对数据进行预处理
- string_replace.py:对获取的数据进行标签替换的类
- SynonymsReplace.py:对数据进行近义词替换的类
- jinyici.txt:为哈工大词林文件	

在主目录下：

- home.py:设定了主页的展示逻辑

- jumpmain2pre.py:设定了跳转逻辑

- PreEdit.py:设定了读取文件、保存文件、编辑文件的逻辑

- sumcreating.py:模型主要嵌合在此，并与进度条绑定

- result.py:展示生成的：标题，文件摘要与关键字，并设定了保存功能

- success.py:设定完成保存的效果界面与跳转逻辑

- TextRank4Keyword.py:设定了对关键字的生成算法

- TextRank3Sente.py：设定了关键语句的生成算法

- util.py:textRank算法的计算模块

  

### 三. 其它说明

1. 在本项目中，为了提升模型的效果，使用了近义词替换算法，原因是当系统遇到未曾遇到过的词语时会标记为_UNK，这样就失去了词语本身的意思，增加了近义词算法的本意是减小在算法输入中的UNK比例。

2. 本项目中生成摘要算法与关键词算法能完美运行，显示效果也很好。但是，虽然使用了大量的数据与时间进行了训练，seq2seq进行标题生成的能力还是有所欠缺，尤其是面临较长的文本内容时，往往需要更大的时间与性能，得到的输出也并不是很好。我们认为训练效果不好的原因有如下几个：
   - 数据源是人为构造的，本身有很大的不确定性，同一篇文章标题可以有很多种，增加了模型本身的歧义；
   - 数据本身有很多噪声，很多文章内容空洞，和标题没有很大联系。有些标题党的文章也会对模型产生不好的影响，而这些数据难以剔除；
   - 算法本身的分词能力还有欠缺，很多关键的词语往往被拆分成两部分，而这两部分在后续的内容几乎不会合在一起；
   - 系统还有不完善，在长时间的迭代后，总体的歧义性不再下降，但是歧义水平还是在较高的水平，可能需要使用其他算法进行优化。

3. 我们对程序进行了打包，在打包的时候发现如果将全部内容打包进一个exe文件，程序本身容易崩溃，所以打包成多文件格式。
4. **程序运行需要在含有各种资源文件的文件夹内进行。为了减小上传文件的大小，我们将seq2seq模型移动到了\dist\papermain\seq2seqAttSum\ckpt下，如需打开代码进行检验效果 ，需要将该模型移动到本项目根目录下，运行predict.py。需要使用哈工大模型，由于该模型十分庞大，这里不再上传，模型文件需要安放在\dist\papermain\ltp_data_v3.4.0\ltp_data_v3.4.0目录下，否则程序无法运行**
5. **程序加载模型的时间比较长，待程序对文件的处理运行到100%后点击关闭窗口即可，结果展示的新窗口会在经过约2s后自动弹出。**
6. 模型的性能优化还是要我们在以后的学习中不断调整完善，希望能够使得模型更具鲁棒性与可靠性。


